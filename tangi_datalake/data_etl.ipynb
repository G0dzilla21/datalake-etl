{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "df = spark.read.format('csv') \\\n",
    "    .option(\"header\", True) \\\n",
    "    .option(\"inferSchema\", True) \\\n",
    "    .load('csv_files/data_lake.csv')\n",
    "\n",
    "df.show(10)\n",
    "df=df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop columns '_c0' and 'Unnamed: 0' as they are uneccesary and provide no useful data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['_c0', 'Unnamed: 0'], inplace=True)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#               TRANSFORM "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FURNITURE DATAFRAME #"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a seperate dataframe that contains all the columns relating to furniture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "furniture_df = df[['item_id', 'name', 'category', 'price5',\\\n",
    "       'old_price', 'sellable_online', 'link', 'other_colors',\\\n",
    "       'short_description', 'designer', 'depth', 'height', 'width']].copy()\n",
    "furniture_df.dropna(subset='item_id', inplace=True)\n",
    "furniture_df.reset_index(inplace=True, drop=True)\n",
    "furniture_df = furniture_df.rename({'price5': 'price'}, axis=1)\n",
    "furniture_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for any rows that contain null values in the Furniture Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "furniture_df[furniture_df.isnull().any(axis=1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the depth, height, and width columns contain some null values for some of the rows.\n",
    "\n",
    "Since the dimensions of the furniture items are already indicated in the short_description column, we can go ahead and drop the depth, height, and width columns as it is just redundant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "furniture_df.drop(columns=['depth', 'height', 'width'], inplace=True)\n",
    "furniture_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's (again) check for any rows that contain null values in the Furniture Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "furniture_df[furniture_df.isnull().any(axis=1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice there are now NO rows which contain any null values.\n",
    "\n",
    "Now let's take a look at the designer column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "furniture_df['designer'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice there are some designers that are actually descriptions. Since there is too many of these mismatched designers, we will drop the designer column in all (due to time, mostly).\n",
    "\n",
    "We will also drop the link column as these links are outdated and no longer working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "furniture_df.drop(columns=['link', 'designer'], inplace=True)\n",
    "furniture_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POKEMON DATAFRAME"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a seperate dataframe that contains all the columns relating to pokemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_df = df[['Pokemon', 'Card Type','Generation', 'Card Number', 'Price19']].copy()\n",
    "pokemon_df.dropna(subset='Pokemon', inplace=True)\n",
    "pokemon_df.reset_index(inplace=True, drop=True)\n",
    "pokemon_df = pokemon_df.rename({'Pokemon': 'name', 'Card Type': 'card_type','Generation': 'generation', 'Card Number': 'card_number','Price19': 'price', }, axis=1)\n",
    "pokemon_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for any rows that contain null values in the Pokemon Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_df[pokemon_df.isnull().any(axis=1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice there are now NO rows which contain any null values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOOK DATAFRAME"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a seperate dataframe that contains all the columns relating to books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df = df[['price5','ranks', 'title', 'no_of_reviews', 'ratings', 'author', 'cover_type', 'year', 'genre' ]].copy()\n",
    "book_df = book_df.dropna(subset='title')\n",
    "book_df.reset_index(inplace=True, drop=True)\n",
    "book_df = book_df.rename({'price5': 'price'}, axis=1)\n",
    "book_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will rename some of the columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for any rows that contain null values in the Book Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df[book_df.isnull().any(axis=1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one record whose genre is None. We can replace it with the correct data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df.loc[1253,'genre'] = \"Non Fiction\"\n",
    "book_df.loc[[1253]]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check (again) for any rows that contain null values in the Book Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df[book_df.isnull().any(axis=1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataframe, there are some mismatch values in columns. Lets try to fix them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the incorrect values in the 'cover type' column: '4.8', 'Dr. Steven R Gundry  MD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df['cover_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df.loc[book_df['cover_type'] == '4.8']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all of the column values for this record are mismatch. So we must put them in their correct spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df.loc[289,'title'] = '\"Moleskine Classic Notebook, Hard Cover, Large (5\"\" x 8.25\"\") Ruled/Lined, Black, 240 Pages\"'\n",
    "book_df.loc[289,'no_of_reviews'] = '22,268'\n",
    "book_df.loc[289,'ratings'] = '4.8'\n",
    "book_df.loc[289,'author'] = \"Moleskine Store\"\n",
    "book_df.loc[289,'cover_type'] = \"Hardcover\"\n",
    "book_df.loc[289,'year'] = \"2018\"\n",
    "book_df.loc[289, 'genre'] = 'Non Fiction'\n",
    "book_df.loc[[289]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df.loc[book_df['cover_type'] == 'Dr. Steven R Gundry  MD']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some research, index: 906 is the incorrect duplicate of index: 867. Therefore we can drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df.drop([906], inplace=True)\n",
    "book_df.loc[book_df['cover_type'] == 'Dr. Steven R Gundry  MD']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fix the mismatching with this row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df.loc[867,'title'] = '\"The Plant Paradox: The Hidden Dangers in \"\"Healthy\"\" Foods That Cause Disease and Weight Gain (The Plant Paradox, 1)\"'\n",
    "book_df.loc[867,'no_of_reviews'] = '14,283'\n",
    "book_df.loc[867,'ratings'] = '4.4'\n",
    "book_df.loc[867,'author'] = \"Dr. Steven R Gundry MD\"\n",
    "book_df.loc[867,'cover_type'] = \"Hardcover\"\n",
    "book_df.loc[867,'year'] = \"2017\"\n",
    "book_df.loc[867, 'genre'] = 'Non Fiction'\n",
    "book_df.loc[[867]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the cover types should be fixed now, and we also got to clean up a lot of mismatched data that was revealed in other columns as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df['cover_type'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the genre column now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df['genre'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there is at least one row whose genre is unknown so let's fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the row with the unknown value in the genre column\n",
    "book_df.loc[book_df['genre'] == 'unknown']\n",
    "\n",
    "# # reassign the value to Non Fiction\n",
    "book_df.loc[713,'genre'] = \"Non Fiction\"\n",
    "\n",
    "# Check to see new genre\n",
    "book_df.iloc[[713]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the genre column should only contain 'Fiction' and 'Non Fiction' as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df['genre'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOOD DATAFRAME"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a seperate dataframe that contains all the columns relating to food."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df = df[['price5', 'date', 'product', 'market', 'size']].copy()\n",
    "food_df = food_df.dropna(subset= ('product', 'market', 'price5'))\n",
    "food_df.reset_index(inplace=True, drop=True)\n",
    "food_df = food_df.rename({'price5': 'price', 'size': 'measurement'}, axis=1)\n",
    "food_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for any rows that contain null values in the Food Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df[food_df.isnull().any(axis=1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice there are now NO rows which contain any null values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the measurement column of the Food Database, and look at the unique values its holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df['measurement'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice there is '1 liter' and 'liter' which are practically the same thing. So we will change '1 liter' to be 'liter'.\n",
    "\n",
    "We will also change '300g' to be 'gram' and 'kg' to be 'kilogram' to keep the measurement naming conventions consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df['measurement'] = np.where((food_df['measurement'] == '1 liter'), \"liter\", food_df['measurement'])\n",
    "food_df['measurement'] = np.where((food_df['measurement'] == '300 g'), \"gram\", food_df['measurement'])\n",
    "food_df['measurement'] = np.where((food_df['measurement'] == 'kg'), \"kilogram\", food_df['measurement'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that all the measurement names are consistent and there are no duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df['measurement'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our clean dataframes, we can load them into their own csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will create new csv files in 'csv_files' folder if they do not already exist\n",
    "furniture_df.to_csv('csv_files/furniture.csv', index=False) \n",
    "pokemon_df.to_csv('csv_files/pokemon.csv', index=False)\n",
    "book_df.to_csv('csv_files/book.csv', index=False)\n",
    "food_df.to_csv('csv_files/food.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
